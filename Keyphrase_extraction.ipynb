{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import resources.dataset as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<resources.semeval2017.SemEval2017 object at 0x7fe897c78630>\n"
     ]
    }
   ],
   "source": [
    "default_corpus = rd.load_corpus()\n",
    "print(default_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: semeval2017-task10\n",
      "Config: {'train-labeled': 'corpus/semeval2017-task10/train2/', 'dev-labeled': 'corpus/semeval2017-task10/dev/', 'test-unlabeled': 'corpus/semeval2017-task10/scienceie2017_test_unlabelled/', 'test-labeled': 'corpus/semeval2017-task10/semeval_articles_test/'}\n",
      "len(Train): 350\n",
      "PoS sequences: 1486\n",
      "PoS sequences example: ('NNS IN DT NN JJ', {'tags': ['NNS', 'IN', 'DT', 'NN', 'JJ'], 'count': 1})\n",
      "len(Dev): 50\n",
      "len(Test): 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", default_corpus.name)\n",
    "print(\"Config:\", default_corpus.config)\n",
    "\n",
    "print(\"len(Train):\", len(default_corpus.train))\n",
    "# print(\"Train:\", default_corpus.train.popitem()[1][\"raw\"][\"txt\"])\n",
    "# print(\"Train:\", default_corpus.train.popitem()[1][\"tags\"])\n",
    "# print(\"Train:\", default_corpus.train.popitem()[1][\"keyphrases\"])\n",
    "print(\"PoS sequences:\", len(default_corpus.pos_sequences))\n",
    "print(\"PoS sequences example:\", default_corpus.pos_sequences.popitem())\n",
    "\n",
    "print(\"len(Dev):\", len(default_corpus.dev))\n",
    "# print(\"Dev:\", default_corpus.dev.popitem()[1][\"raw\"][\"txt\"])\n",
    "\n",
    "print(\"len(Test):\", len(default_corpus.test))\n",
    "# print(\"Test:\", default_corpus.test.popitem()[1][\"raw\"][\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, train = default_corpus.train.popitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n\".join([str(ann) for ann in train[\"tags\"]]))\n",
    "# print(\"\\n\".join([str(keyphrase) for keyphrase in train[\"keyphrases\"].items()]))\n",
    "# print(\"\\n\".join([str(ac) for ac in default_corpus.annotated_candidates_spans[key]]))\n",
    "# print(\"Candidates\", len(default_corpus.annotated_candidates_spans[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of each PoS Sequence [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 34, 37, 39, 50, 63, 89, 103, 107, 130, 177, 200, 219, 283, 335, 444, 526, 627, 684]\n"
     ]
    }
   ],
   "source": [
    "default_corpus.load_pos_sequences()\n",
    "pos_sequences = default_corpus.pos_sequences\n",
    "# pos_sequences = {str(key): value for key, value in filter(lambda ps: ps[1][\"count\"] > 1, default_corpus.pos_sequences.items())}\n",
    "# for value in pos_sequences.items():\n",
    "#    print(value)\n",
    "filter_limits = sorted(set([pos_seq[\"count\"] for pos_seq in pos_sequences.values()]))\n",
    "print(\"Occurrences of each PoS Sequence\", filter_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document example...\n",
      "\n",
      "Name: S0304399111001811\n",
      "Content:\n",
      " We have developed the theory of electrons carrying quantized orbital angular momentum. To make connection to realistic situations, we considered a plane wave moving along the optic axis of a lens system, intercepted by a round, centered aperture.88In the experiment, this aperture carries the holographic mask. It turns out that the movement along the optic axis can be separated off; the reduced Schrödinger equation operating in the plane of the aperture can be mapped onto Bessel's differential equation. The ensuing eigenfunctions fall into families with discrete orbital angular momentum ℏm along the optic axis where m is a magnetic quantum number. Those vortices can be produced by matching a plane wave after passage through a holographic mask with a fork dislocation to the eigenfunctions of the cylindrical problem. Vortices can be focussed by magnetic lenses into volcano-like charge distributions with very narrow angular divergence, resembling loop currents in the diffraction plane. Inclusion of spherical aberration changes the ringlike shape but does not destroy the central zero intensity of vortices with m≠0. Partial coherence of the incident wave leads to a rise of the central intensity minimum. It is shown that a very small source angle (i.e. a very high coherence) is necessary so as to keep the volcano structure intact. Their small angular width in the far field may allow the creation of nm-sized or smaller electron vortices but the demand for extremely high coherence of the source poses a serious difficulty.\n",
      "\n",
      "Labeled keyphrases:\n",
      " [('T4', ('KEYPHRASE', (293, 309)), 'holographic mask'), ('T10', ('KEYPHRASE', (735, 751)), 'holographic mask'), ('T11', ('KEYPHRASE', (805, 824)), 'cylindrical problem'), ('T14', ('KEYPHRASE', (1010, 1030)), 'spherical aberration'), ('T28', ('KEYPHRASE', (978, 995)), 'diffraction plane'), ('T101', ('KEYPHRASE', (875, 908)), 'volcano-like charge distributions'), ('T106', ('KEYPHRASE', (32, 41)), 'electrons'), ('T234', ('KEYPHRASE', (389, 427)), 'reduced Schrödinger equation operating'), ('T255', ('KEYPHRASE', (997, 1030)), 'Inclusion of spherical aberration'), ('T268', ('KEYPHRASE', (735, 775)), 'holographic mask with a fork dislocation')]\n",
      "\n",
      "Keyphrases in %s.ann: S0304399111001811\n",
      "T4\tKEYPHRASE 293 309\tholographic mask\n",
      "T10\tKEYPHRASE 735 751\tholographic mask\n",
      "T11\tKEYPHRASE 805 824\tcylindrical problem\n",
      "T14\tKEYPHRASE 1010 1030\tspherical aberration\n",
      "T28\tKEYPHRASE 978 995\tdiffraction plane\n",
      "T101\tKEYPHRASE 875 908\tvolcano-like charge distributions\n",
      "T106\tKEYPHRASE 32 41\telectrons\n",
      "T234\tKEYPHRASE 389 427\treduced Schrödinger equation operating\n",
      "T255\tKEYPHRASE 997 1030\tInclusion of spherical aberration\n",
      "T268\tKEYPHRASE 735 775\tholographic mask with a fork dislocation\n"
     ]
    }
   ],
   "source": [
    "key = list(default_corpus.test.keys())[1]\n",
    "text = default_corpus.test[key][\"raw\"][\"txt\"]\n",
    "\n",
    "print(\"Document example...\\n\")\n",
    "print(\"Name:\", key)\n",
    "print(\"Content:\\n\", text)\n",
    "\n",
    "# Train or load model\n",
    "default_corpus.training(filter_min_count=3)\n",
    "# Labeling\n",
    "keyphrases = default_corpus.label_text(text)\n",
    "\n",
    "print(\"Labeled keyphrases:\\n\", keyphrases)\n",
    "print(\"\\nKeyphrases in %s.ann:\", key)\n",
    "print(rd.keyphrases2brat(keyphrases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of how to save answer to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 1\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 2\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 3\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 4\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 5\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 6\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 7\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 8\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 9\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 10\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 11\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 12\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 13\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 14\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 15\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 16\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 17\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 20\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 21\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 22\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 24\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 25\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 26\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 27\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 28\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 34\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 37\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 39\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 50\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 63\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 89\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 103\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 107\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 130\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 177\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 200\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 219\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 283\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 335\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 444\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 526\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 627\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 684\n"
     ]
    }
   ],
   "source": [
    "for fl in filter_limits:\n",
    "    default_corpus.training(filter_min_count=fl)\n",
    "    output = \"output-dev/%s/\" % fl\n",
    "    if not rd.path_exists(output):\n",
    "        os.makedirs(output)\n",
    "    for i, (key, tmp_dataset) in enumerate(default_corpus.dev.items()):\n",
    "        text = tmp_dataset[\"raw\"][\"txt\"]\n",
    "        keyphrases = default_corpus.label_text(text)\n",
    "        with open(output + key + \".ann\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "        with open(output + key + \".txt\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "    print(\"Written docs: %d \\\n",
    "          \\n - Minimum occurence of PoS sequences to train the model: %d\" % (i + 1, fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 1\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 2\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 3\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 4\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 5\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 6\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 7\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 8\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 9\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 10\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 11\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 12\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 13\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 14\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 15\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 16\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 17\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 20\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 21\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 22\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 24\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 25\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 26\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 27\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 28\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 34\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 37\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 39\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 50\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 63\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 89\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 103\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 107\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 130\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 177\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 200\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 219\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 283\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 335\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 444\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 526\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 627\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 684\n"
     ]
    }
   ],
   "source": [
    "for fl in filter_limits:\n",
    "    default_corpus.training(filter_min_count=fl)\n",
    "    output = \"output-test/%s/\" % fl\n",
    "    if not rd.path_exists(output):\n",
    "        os.makedirs(output)\n",
    "    for i, (key, tmp_dataset) in enumerate(default_corpus.test.items()):\n",
    "        text = tmp_dataset[\"raw\"][\"txt\"]\n",
    "        keyphrases = default_corpus.label_text(text)\n",
    "        with open(output + key + \".ann\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "        with open(output + key + \".txt\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "    print(\"Written docs: %d \\\n",
    "          \\n - Minimum occurence of PoS sequences to train the model: %d\" % (i + 1, fl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
