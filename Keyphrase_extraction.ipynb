{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kephrase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module to load corpus and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resources.dataset as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus\n",
    "\n",
    "To load the corpus the following Method is used.\n",
    "\n",
    "```\n",
    "rd.load_corpus()\n",
    "```\n",
    "With this method the file content of a dataset is loaded in memory and PoS tag sequences are extracted from the train dataset.   \n",
    "\n",
    "The corpus loaded by default is [SemEval 2017 Task 10](https://scienceie.github.io/resources.html), at the moment it is the only one available. Files for this dataset should be included in the package under the path configured in config/config.py (Default: corpus/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<resources.semeval2017.SemEval2017 object at 0x7f21036b7908>\n"
     ]
    }
   ],
   "source": [
    "default_corpus = rd.load_corpus()\n",
    "print(default_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: semeval2017-task10\n",
      "Config: {'train-labeled': 'corpus/semeval2017-task10/train2/', 'dev-labeled': 'corpus/semeval2017-task10/dev/', 'test-unlabeled': 'corpus/semeval2017-task10/scienceie2017_test_unlabelled/', 'test-labeled': 'corpus/semeval2017-task10/semeval_articles_test/'}\n",
      "len(Train): 350\n",
      "PoS sequences: 1486\n",
      "PoS sequences example: ('NNS IN DT NN JJ', {'tags': ['NNS', 'IN', 'DT', 'NN', 'JJ'], 'count': 1})\n",
      "len(Dev): 50\n",
      "len(Test): 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", default_corpus.name)\n",
    "print(\"Config:\", default_corpus.config)\n",
    "\n",
    "print(\"len(Train):\", len(default_corpus.train))\n",
    "# print(\"Train:\", default_corpus.train.popitem()[1][\"raw\"][\"txt\"])\n",
    "# print(\"Train:\", default_corpus.train.popitem()[1][\"tags\"])\n",
    "# print(\"Train:\", default_corpus.train.popitem()[1][\"keyphrases\"])\n",
    "print(\"PoS sequences:\", len(default_corpus.pos_sequences))\n",
    "print(\"PoS sequences example:\", default_corpus.pos_sequences.popitem())\n",
    "\n",
    "print(\"len(Dev):\", len(default_corpus.dev))\n",
    "# print(\"Dev:\", default_corpus.dev.popitem()[1][\"raw\"][\"txt\"])\n",
    "\n",
    "print(\"len(Test):\", len(default_corpus.test))\n",
    "# print(\"Test:\", default_corpus.test.popitem()[1][\"raw\"][\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key, train = default_corpus.train.popitem()\n",
    "# print(\"\\n\".join([str(ann) for ann in train[\"tags\"]]))\n",
    "# print(\"\\n\".join([str(keyphrase) for keyphrase in train[\"keyphrases\"].items()]))\n",
    "# print(\"\\n\".join([str(ac) for ac in default_corpus.annotated_candidates_spans[key]]))\n",
    "# print(\"Candidates\", len(default_corpus.annotated_candidates_spans[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoS tag sequences\n",
    "\n",
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_corpus.load_pos_sequences()\n",
    "pos_sequences = default_corpus.pos_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of PoS sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('JJ NN', {'tags': ['JJ', 'NN'], 'count': 526})\n",
      "('NN NN', {'tags': ['NN', 'NN'], 'count': 444})\n",
      "('NN IN NN NN', {'tags': ['NN', 'IN', 'NN', 'NN'], 'count': 9})\n",
      "('VBN NN VBZ VBN', {'tags': ['VBN', 'NN', 'VBZ', 'VBN'], 'count': 1})\n",
      "('NN TO VB PRP$ NN CC NN NN NNS', {'tags': ['NN', 'TO', 'VB', 'PRP$', 'NN', 'CC', 'NN', 'NN', 'NNS'], 'count': 1})\n",
      "('NN', {'tags': ['NN'], 'count': 684})\n",
      "('JJ NN NN', {'tags': ['JJ', 'NN', 'NN'], 'count': 200})\n",
      "('JJ NNS JJ JJ NN', {'tags': ['JJ', 'NNS', 'JJ', 'JJ', 'NN'], 'count': 1})\n",
      "('NN NN NN', {'tags': ['NN', 'NN', 'NN'], 'count': 89})\n",
      "('JJ NN IN JJ JJ NNS', {'tags': ['JJ', 'NN', 'IN', 'JJ', 'JJ', 'NNS'], 'count': 2})\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([str(pos_seq) for pos_seq in pos_sequences.items()][:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following counts are used as limits to select the PoS sequences to train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of keyphrase extraction\n",
    "\n",
    "Example of text from the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document example...\n",
      "\n",
      "Name of document: S0304399111001811\n",
      "Content to label:\n",
      "\n",
      " We have developed the theory of electrons carrying quantized orbital angular momentum. To make connection to realistic situations, we considered a plane wave moving along the optic axis of a lens system, intercepted by a round, centered aperture.88In the experiment, this aperture carries the holographic mask. It turns out that the movement along the optic axis can be separated off; the reduced Schrödinger equation operating in the plane of the aperture can be mapped onto Bessel's differential equation. The ensuing eigenfunctions fall into families with discrete orbital angular momentum ℏm along the optic axis where m is a magnetic quantum number. Those vortices can be produced by matching a plane wave after passage through a holographic mask with a fork dislocation to the eigenfunctions of the cylindrical problem. Vortices can be focussed by magnetic lenses into volcano-like charge distributions with very narrow angular divergence, resembling loop currents in the diffraction plane. Inclusion of spherical aberration changes the ringlike shape but does not destroy the central zero intensity of vortices with m≠0. Partial coherence of the incident wave leads to a rise of the central intensity minimum. It is shown that a very small source angle (i.e. a very high coherence) is necessary so as to keep the volcano structure intact. Their small angular width in the far field may allow the creation of nm-sized or smaller electron vortices but the demand for extremely high coherence of the source poses a serious difficulty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key = list(default_corpus.test.keys())[1]\n",
    "text = default_corpus.test[key][\"raw\"][\"txt\"]\n",
    "\n",
    "print(\"Document example...\\n\")\n",
    "print(\"Name of document:\", key)\n",
    "print(\"Content to label:\\n\\n\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or load model\n",
    "\n",
    "Train before labeling with the following method.\n",
    "\n",
    "The following parameter is recomended, it is used to select the PoS sequences to filter candidates to train the CRF model. \n",
    "\n",
    "```\n",
    "filter_min_count = 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load model\n",
    "default_corpus.training(filter_min_count=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label text\n",
    "\n",
    "To label text with the trained model use the following method.\n",
    "```\n",
    "default_corpus.label_text(text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling\n",
    "keyphrases = default_corpus.label_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyphrases are returned as a list describing the keyphrase. \n",
    "\n",
    "Each element is a tuple with fields.\n",
    "```\n",
    "(\"Keyphrase ID\", (\"Label\", Start, End), \"Text of keyphrase\")\n",
    "    string         string   int   int        string \n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "[\n",
    "    ('T4', ('KEYPHRASE', (293, 309)), 'holographic mask'), \n",
    "    ('T10', ('KEYPHRASE', (735, 751)), 'holographic mask')\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of labeled keyphrases:\n",
      "\n",
      " [('T4', ('KEYPHRASE', (293, 309)), 'holographic mask'), ('T10', ('KEYPHRASE', (735, 751)), 'holographic mask'), ('T11', ('KEYPHRASE', (805, 824)), 'cylindrical problem'), ('T14', ('KEYPHRASE', (1010, 1030)), 'spherical aberration'), ('T28', ('KEYPHRASE', (978, 995)), 'diffraction plane'), ('T101', ('KEYPHRASE', (875, 908)), 'volcano-like charge distributions'), ('T106', ('KEYPHRASE', (32, 41)), 'electrons'), ('T234', ('KEYPHRASE', (389, 427)), 'reduced Schrödinger equation operating'), ('T255', ('KEYPHRASE', (997, 1030)), 'Inclusion of spherical aberration'), ('T268', ('KEYPHRASE', (735, 775)), 'holographic mask with a fork dislocation')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of labeled keyphrases:\\n\\n\", keyphrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result could be formated as [brat](http://brat.nlplab.org/examples.html#annotation-examples) with the method.\n",
    "\n",
    "```\n",
    "rd.keyphrases2brat(keyphrases)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keyphrases in S0304399111001811.ann:\n",
      "\n",
      "T4\tKEYPHRASE 293 309\tholographic mask\n",
      "T10\tKEYPHRASE 735 751\tholographic mask\n",
      "T11\tKEYPHRASE 805 824\tcylindrical problem\n",
      "T14\tKEYPHRASE 1010 1030\tspherical aberration\n",
      "T28\tKEYPHRASE 978 995\tdiffraction plane\n",
      "T101\tKEYPHRASE 875 908\tvolcano-like charge distributions\n",
      "T106\tKEYPHRASE 32 41\telectrons\n",
      "T234\tKEYPHRASE 389 427\treduced Schrödinger equation operating\n",
      "T255\tKEYPHRASE 997 1030\tInclusion of spherical aberration\n",
      "T268\tKEYPHRASE 735 775\tholographic mask with a fork dislocation\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKeyphrases in %s.ann:\\n\" % key)\n",
    "\n",
    "print(rd.keyphrases2brat(keyphrases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of how to save answer to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible values to select PoS sequences are the counts of occurrences of each PoS sequence in the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of each PoS Sequence in the train dataset\n",
      " [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 34, 37, 39, 50, 63, 89, 103, 107, 130, 177, 200, 219, 283, 335, 444, 526, 627, 684]\n"
     ]
    }
   ],
   "source": [
    "filter_limits = sorted(set([pos_seq[\"count\"] for pos_seq in pos_sequences.values()]))\n",
    "print(\"Occurrences of each PoS Sequence in the train dataset\\n\", filter_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples iterates over the dev and tests dataset for SemEval 2017 Task 10, the outputs are saved under output-dev/ and output-test/ in the main directory of this package. The results an be evaluated using the script ./eval_example_output_semeval2017.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 1\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 2\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 3\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 4\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 5\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 6\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 7\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 8\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 9\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 10\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 11\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 12\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 13\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 14\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 15\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 16\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 17\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 20\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 21\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 22\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 24\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 25\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 26\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 27\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 28\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 34\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 37\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 39\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 50\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 63\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 89\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 103\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 107\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 130\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 177\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 200\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 219\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 283\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 335\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 444\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 526\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 627\n",
      "Written docs: 50           \n",
      " - Minimum occurence of PoS sequences to train the model: 684\n"
     ]
    }
   ],
   "source": [
    "for fl in filter_limits:\n",
    "    default_corpus.training(filter_min_count=fl)\n",
    "    output = \"output-dev/%s/\" % fl\n",
    "    if not rd.path_exists(output):\n",
    "        os.makedirs(output)\n",
    "    for i, (key, tmp_dataset) in enumerate(default_corpus.dev.items()):\n",
    "        text = tmp_dataset[\"raw\"][\"txt\"]\n",
    "        keyphrases = default_corpus.label_text(text)\n",
    "        with open(output + key + \".ann\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "        with open(output + key + \".txt\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "    print(\"Written docs: %d \\\n",
    "          \\n - Minimum occurence of PoS sequences to train the model: %d\" % (i + 1, fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 1\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 2\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 3\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 4\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 5\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 6\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 7\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 8\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 9\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 10\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 11\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 12\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 13\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 14\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 15\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 16\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 17\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 20\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 21\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 22\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 24\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 25\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 26\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 27\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 28\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 34\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 37\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 39\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 50\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 63\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 89\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 103\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 107\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 130\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 177\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 200\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 219\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 283\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 335\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 444\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 526\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 627\n",
      "Written docs: 100           \n",
      " - Minimum occurence of PoS sequences to train the model: 684\n"
     ]
    }
   ],
   "source": [
    "for fl in filter_limits:\n",
    "    default_corpus.training(filter_min_count=fl)\n",
    "    output = \"output-test/%s/\" % fl\n",
    "    if not rd.path_exists(output):\n",
    "        os.makedirs(output)\n",
    "    for i, (key, tmp_dataset) in enumerate(default_corpus.test.items()):\n",
    "        text = tmp_dataset[\"raw\"][\"txt\"]\n",
    "        keyphrases = default_corpus.label_text(text)\n",
    "        with open(output + key + \".ann\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "        with open(output + key + \".txt\", \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(rd.keyphrases2brat(keyphrases))\n",
    "    print(\"Written docs: %d \\\n",
    "          \\n - Minimum occurence of PoS sequences to train the model: %d\" % (i + 1, fl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
